---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 169
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: '{"name":"TestAccDataSourceModel_Custom","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","source":{"url":"https://huggingface.co/agentica-org/DeepCoder-14B-Preview"}}'
        form: {}
        headers:
            Content-Type:
                - application/json
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models
        method: POST
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1588
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":0,"status":"preparing","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1588"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:42:37 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 87e39267-c84a-4d4c-94ca-53a386f63737
        status: 200 OK
        code: 200
        duration: 785.254458ms
    - id: 1
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1588
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":0,"status":"preparing","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1588"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:42:37 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 6e28e08f-791c-4db8-bc25-f1e74ffcff23
        status: 200 OK
        code: 200
        duration: 202.767208ms
    - id: 2
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1588
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":0,"status":"preparing","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1588"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:43:37 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 44f439e2-45a9-4f56-b45a-7c451efdfc9f
        status: 200 OK
        code: 200
        duration: 102.233458ms
    - id: 3
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1588
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":0,"status":"preparing","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1588"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:44:37 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 95edd0af-1a59-4f17-96dd-c4eafee56685
        status: 200 OK
        code: 200
        duration: 95.121792ms
    - id: 4
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1588
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":0,"status":"preparing","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1588"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:45:37 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - d10654dc-7e5e-43f5-be9a-667fa09371a4
        status: 200 OK
        code: 200
        duration: 183.46525ms
    - id: 5
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1588
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":0,"status":"preparing","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1588"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:46:38 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge03)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - cf448fe6-4f4f-42df-b41c-b29404cd938b
        status: 200 OK
        code: 200
        duration: 187.352708ms
    - id: 6
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:38 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 609c09ed-8b01-4726-92fa-7516edafe82b
        status: 200 OK
        code: 200
        duration: 109.411583ms
    - id: 7
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:38 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 6251bb89-1047-4fba-9c29-6a3982169e6a
        status: 200 OK
        code: 200
        duration: 67.107ms
    - id: 8
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:38 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 7c1ee214-4d0a-45c1-9272-6e3847083596
        status: 200 OK
        code: 200
        duration: 47.381625ms
    - id: 9
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:39 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - db935394-8cfb-48ef-8a92-204816754689
        status: 200 OK
        code: 200
        duration: 93.608667ms
    - id: 10
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:40 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 51ac4370-3e64-4657-b5b9-d977bcac93d1
        status: 200 OK
        code: 200
        duration: 44.921625ms
    - id: 11
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 51893
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":30}'
        headers:
            Content-Length:
                - "51893"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:40 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 47b91eb7-32cf-4330-8b48-91969f5ec313
        status: 200 OK
        code: 200
        duration: 195.04675ms
    - id: 12
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:40 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - a195b5ff-28e6-4e2f-be18-4d98c139bc33
        status: 200 OK
        code: 200
        duration: 39.400333ms
    - id: 13
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 51893
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":30}'
        headers:
            Content-Length:
                - "51893"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:40 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 81e6f7ed-4892-4798-9853-26382f970777
        status: 200 OK
        code: 200
        duration: 214.294875ms
    - id: 14
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:40 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 6edfb21d-e561-474b-b5b0-f713d599bb55
        status: 200 OK
        code: 200
        duration: 37.8305ms
    - id: 15
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:41 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 7c96d410-ab5d-481d-93b2-0d380694c8cb
        status: 200 OK
        code: 200
        duration: 48.426208ms
    - id: 16
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 51893
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":30}'
        headers:
            Content-Length:
                - "51893"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:41 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 18b9df43-a02d-4f0b-b50b-9b14f59ee01b
        status: 200 OK
        code: 200
        duration: 182.948833ms
    - id: 17
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:41 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 045e110a-bd86-4378-b0d8-32961b8624ea
        status: 200 OK
        code: 200
        duration: 48.260083ms
    - id: 18
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:42 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 16287391-d324-473b-abfc-d7a06638db1b
        status: 200 OK
        code: 200
        duration: 64.98525ms
    - id: 19
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 51893
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":30}'
        headers:
            Content-Length:
                - "51893"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:42 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 58c8f99e-95b0-4598-ae22-0f1a28c34fa2
        status: 200 OK
        code: 200
        duration: 206.674083ms
    - id: 20
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:42 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - ef4b9004-f023-4082-918f-4d40ab102c5d
        status: 200 OK
        code: 200
        duration: 50.609125ms
    - id: 21
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 51893
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":30}'
        headers:
            Content-Length:
                - "51893"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:43 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 01bbfc81-cd51-4d96-96a8-66345710625e
        status: 200 OK
        code: 200
        duration: 157.656834ms
    - id: 22
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:43 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - c50dd06d-b3ae-4107-be31-404e8c19f068
        status: 200 OK
        code: 200
        duration: 40.353708ms
    - id: 23
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1594
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:42:37.110629Z","description":"","has_eula":false,"id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","name":"TestAccDataSourceModel_Custom","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725385,"status":"ready","tags":["custom"],"updated_at":null}'
        headers:
            Content-Length:
                - "1594"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:43 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 77ee5ed7-53ff-4c80-9dd8-9805863b8307
        status: 200 OK
        code: 200
        duration: 48.764625ms
    - id: 24
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: DELETE
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 0
        uncompressed: false
        body: ""
        headers:
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:43 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 866cc1b1-304f-45f7-92d4-0b0caa5cb1a4
        status: 204 No Content
        code: 204
        duration: 157.280542ms
    - id: 25
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 126
        uncompressed: false
        body: '{"message":"resource is not found","resource":"Model","resource_id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","type":"not_found"}'
        headers:
            Content-Length:
                - "126"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:44 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - fe2e437f-6dbe-4977-952c-4431b33aa289
        status: 404 Not Found
        code: 404
        duration: 26.940583ms
    - id: 26
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/929553e1-1b34-45d7-8a67-67d1e7147ef6
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 126
        uncompressed: false
        body: '{"message":"resource is not found","resource":"Model","resource_id":"929553e1-1b34-45d7-8a67-67d1e7147ef6","type":"not_found"}'
        headers:
            Content-Length:
                - "126"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:47:44 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 9a8ca6f9-27fd-4f8b-a29c-d0ca2f1838cc
        status: 404 Not Found
        code: 404
        duration: 24.155459ms
