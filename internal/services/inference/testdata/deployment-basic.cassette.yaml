---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:52:49 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - c8f640c2-9e3e-40c6-83ca-9be4b7c6f652
        status: 200 OK
        code: 200
        duration: 358.939417ms
    - id: 1
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/7205dbce-cc80-4b2a-bb7f-3fd3a804afc3
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1723
        uncompressed: false
        body: '{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"}'
        headers:
            Content-Length:
                - "1723"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:52:49 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - afe3de9a-a703-4809-ac07-e6b20ce53a46
        status: 200 OK
        code: 200
        duration: 147.549708ms
    - id: 2
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:52:50 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - c86be0b2-ce70-4425-b603-76ef7a9e6983
        status: 200 OK
        code: 200
        duration: 178.915708ms
    - id: 3
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/7205dbce-cc80-4b2a-bb7f-3fd3a804afc3
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1723
        uncompressed: false
        body: '{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"}'
        headers:
            Content-Length:
                - "1723"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:52:50 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 6f5d8043-2c7c-4c8f-bca2-01fc800349ae
        status: 200 OK
        code: 200
        duration: 25.847625ms
    - id: 4
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 278
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: '{"name":"test-inference-deployment-basic","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","accept_eula":true,"node_type_name":"L4","tags":[],"min_size":1,"max_size":1,"endpoints":[{"public_network":{},"disable_auth":false}]}'
        form: {}
        headers:
            Content-Type:
                - application/json
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments
        method: POST
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 624
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"creating","tags":[],"updated_at":null}'
        headers:
            Content-Length:
                - "624"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:52:51 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 5f706c2b-1ccd-4003-a725-6520e6ddc95c
        status: 200 OK
        code: 200
        duration: 201.534583ms
    - id: 5
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 624
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"creating","tags":[],"updated_at":null}'
        headers:
            Content-Length:
                - "624"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:52:51 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - cd7e871a-834f-4006-af94-2d2944a7d7bc
        status: 200 OK
        code: 200
        duration: 58.44875ms
    - id: 6
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 624
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"creating","tags":[],"updated_at":null}'
        headers:
            Content-Length:
                - "624"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:53:51 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - e253be30-6c77-458c-bf85-6880b87c874e
        status: 200 OK
        code: 200
        duration: 133.146666ms
    - id: 7
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 624
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"creating","tags":[],"updated_at":null}'
        headers:
            Content-Length:
                - "624"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:54:51 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 33b1402e-2c0d-4dea-bf8e-26b61b1c8c60
        status: 200 OK
        code: 200
        duration: 109.249709ms
    - id: 8
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:56:08 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 35f20d1d-02ee-4f99-9a9d-406f61bbf52c
        status: 200 OK
        code: 200
        duration: 254.926917ms
    - id: 9
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:57:09 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - ce2f18ab-891b-4350-952e-ff23717a998f
        status: 200 OK
        code: 200
        duration: 87.476083ms
    - id: 10
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:58:09 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge03)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 19ab7250-5349-4f37-83f9-6f20a91d1db4
        status: 200 OK
        code: 200
        duration: 81.852959ms
    - id: 11
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 08:59:10 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - bfaafaa8-08bc-4c09-9a7e-c6ac17d39539
        status: 200 OK
        code: 200
        duration: 1.100722292s
    - id: 12
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:00:10 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 6d03b15a-c9b8-4601-8d5d-d02f3e22718a
        status: 200 OK
        code: 200
        duration: 97.321208ms
    - id: 13
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:01:10 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 144a0f6e-ae62-4c92-a6ab-f2164665787c
        status: 200 OK
        code: 200
        duration: 101.9215ms
    - id: 14
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:02:10 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge03)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - d63ffc83-7a0f-4229-b86a-d866ab5dfa70
        status: 200 OK
        code: 200
        duration: 121.971875ms
    - id: 15
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:03:10 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - cb9f39bc-d85e-44d9-b8e2-e79fb86849d9
        status: 200 OK
        code: 200
        duration: 96.822583ms
    - id: 16
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:04:10 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge03)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - cf5c38e9-7ab2-4a6c-bbd6-e0c87dca7d9f
        status: 200 OK
        code: 200
        duration: 75.637708ms
    - id: 17
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 670
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":0,"status":"deploying","tags":[],"updated_at":"2025-05-15T08:55:56.629724Z"}'
        headers:
            Content-Length:
                - "670"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:05:10 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 754f3229-b9c6-4eac-bcdf-6ffe23f465cf
        status: 200 OK
        code: 200
        duration: 123.70525ms
    - id: 18
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 666
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":1,"status":"ready","tags":[],"updated_at":"2025-05-15T09:05:15.085852Z"}'
        headers:
            Content-Length:
                - "666"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:11 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - f6453bcf-1be7-47d2-8fe9-d81a90c7a3a6
        status: 200 OK
        code: 200
        duration: 110.141542ms
    - id: 19
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 666
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":1,"status":"ready","tags":[],"updated_at":"2025-05-15T09:05:15.085852Z"}'
        headers:
            Content-Length:
                - "666"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:11 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 2edddd96-4b35-42f0-81da-7cf77c32cade
        status: 200 OK
        code: 200
        duration: 57.876084ms
    - id: 20
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 666
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":1,"status":"ready","tags":[],"updated_at":"2025-05-15T09:05:15.085852Z"}'
        headers:
            Content-Length:
                - "666"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:11 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 865320e9-3813-4766-8587-cf137cd1a1e3
        status: 200 OK
        code: 200
        duration: 48.350334ms
    - id: 21
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:12 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - b4f0b99a-846e-4b10-bbf8-93066e61df6a
        status: 200 OK
        code: 200
        duration: 588.501084ms
    - id: 22
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/7205dbce-cc80-4b2a-bb7f-3fd3a804afc3
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1723
        uncompressed: false
        body: '{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"}'
        headers:
            Content-Length:
                - "1723"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:12 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - f0cd64cc-c61a-4ba9-8859-cd01a925f125
        status: 200 OK
        code: 200
        duration: 136.611542ms
    - id: 23
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:13 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 009ab078-d1c5-4468-97db-a6ff0a1b47ec
        status: 200 OK
        code: 200
        duration: 221.551333ms
    - id: 24
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/7205dbce-cc80-4b2a-bb7f-3fd3a804afc3
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1723
        uncompressed: false
        body: '{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"}'
        headers:
            Content-Length:
                - "1723"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:13 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 09dbaddb-f519-481b-9268-2a0d573f474b
        status: 200 OK
        code: 200
        duration: 53.621292ms
    - id: 25
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 666
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":1,"status":"ready","tags":[],"updated_at":"2025-05-15T09:05:15.085852Z"}'
        headers:
            Content-Length:
                - "666"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:13 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 6f1fe9d6-410b-460e-8f60-4824e36cecec
        status: 200 OK
        code: 200
        duration: 54.081292ms
    - id: 26
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:13 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 46184f73-2e15-4960-9ae8-e468a421009f
        status: 200 OK
        code: 200
        duration: 210.549916ms
    - id: 27
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/7205dbce-cc80-4b2a-bb7f-3fd3a804afc3
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1723
        uncompressed: false
        body: '{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"}'
        headers:
            Content-Length:
                - "1723"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:13 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 229d2c3c-ffa1-400a-a75f-b702f2f80c21
        status: 200 OK
        code: 200
        duration: 35.025125ms
    - id: 28
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 666
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":1,"status":"ready","tags":[],"updated_at":"2025-05-15T09:05:15.085852Z"}'
        headers:
            Content-Length:
                - "666"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:14 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 1678bd93-4ba7-4835-b5cc-6bcf8c34986a
        status: 200 OK
        code: 200
        duration: 398.651667ms
    - id: 29
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: DELETE
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 669
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":1,"status":"deleting","tags":[],"updated_at":"2025-05-15T09:05:15.085852Z"}'
        headers:
            Content-Length:
                - "669"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:15 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - d8d59438-49e7-4f5c-81ce-69c3d3b695d4
        status: 200 OK
        code: 200
        duration: 357.046542ms
    - id: 30
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 669
        uncompressed: false
        body: '{"created_at":"2025-05-15T08:52:50.831593Z","endpoints":[{"disable_auth":false,"id":"456167a1-2cda-4080-b529-16b7b9bb6e36","public_network":{},"url":"https://4ef1f64f-1d16-472c-a5d9-a40a55424e4e.ifr.fr-par.scaleway.com"}],"error_message":"","id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","max_size":1,"min_size":1,"model_id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","model_name":"meta/llama-3.1-8b-instruct:bf16","name":"test-inference-deployment-basic","node_type_name":"L4","project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","quantization":{"bits":16},"region":"fr-par","size":1,"status":"deleting","tags":[],"updated_at":"2025-05-15T09:05:15.085852Z"}'
        headers:
            Content-Length:
                - "669"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:06:15 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge01)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - d2165c78-86a1-443a-8d8a-d20f0c36094a
        status: 200 OK
        code: 200
        duration: 57.455333ms
    - id: 31
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 131
        uncompressed: false
        body: '{"message":"resource is not found","resource":"deployment","resource_id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","type":"not_found"}'
        headers:
            Content-Length:
                - "131"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:07:15 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge03)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - ae7e3f1b-e162-47ea-94c2-4cf0fe01ca1b
        status: 404 Not Found
        code: 404
        duration: 60.293333ms
    - id: 32
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/deployments/4ef1f64f-1d16-472c-a5d9-a40a55424e4e
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 131
        uncompressed: false
        body: '{"message":"resource is not found","resource":"deployment","resource_id":"4ef1f64f-1d16-472c-a5d9-a40a55424e4e","type":"not_found"}'
        headers:
            Content-Length:
                - "131"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Thu, 15 May 2025 09:07:15 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge03)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 6fbcb2a4-6356-4b53-bb79-ed222d861500
        status: 404 Not Found
        code: 404
        duration: 37.401375ms
