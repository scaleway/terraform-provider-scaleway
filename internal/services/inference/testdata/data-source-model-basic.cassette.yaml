---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    form:
      order_by:
      - display_rank_asc
      page_size:
      - "1000"
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 66736
    body: "{\"models\":[{\"id\":\"5c40e594-d40d-452a-991e-5082225155e1\",\"name\":\"google/gemma-3-27b-it:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-04-04T13:11:00.900800Z\",\"updated_at\":\"2025-06-17T09:31:04.122362Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":80000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":54904369444,\"region\":\"fr-par\"},{\"id\":\"4b239330-99eb-4204-af4a-7751756d7c68\",\"name\":\"google/gemma-3-27b-it:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-07-07T19:59:36.326470Z\",\"updated_at\":\"2025-07-07T19:59:45.224797Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":10000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":29313782550,\"region\":\"fr-par\"},{\"id\":\"ed77954f-3a10-49d9-83b8-6b4928c53226\",\"name\":\"openai/gpt-oss-120b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:12.380302Z\",\"updated_at\":\"2025-08-06T09:32:29.360479Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":195764056107,\"region\":\"fr-par\"},{\"id\":\"41c23555-49d1-466d-9008-4656950bc797\",\"name\":\"openai/gpt-oss-20b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:14.686335Z\",\"updated_at\":\"2025-08-06T08:41:10.511923Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":41301481015,\"region\":\"fr-par\"},{\"id\":\"bd2fd3e8-cd89-4b78-b01d-470c78eb4186\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-26T12:45:37.591726Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"59d67ccb-983f-44da-8f86-646cf833d35d\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-25T15:20:50.096009Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"a51ce791-9546-4c28-aa44-24850d84778b\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:11.513249Z\",\"updated_at\":\"2025-07-21T09:57:24.492248Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":39000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":16070465043,\"region\":\"fr-par\"},{\"id\":\"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:14.190404Z\",\"updated_at\":\"2025-07-21T09:57:25.611961Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9093169346,\"region\":\"fr-par\"},{\"id\":\"efcf0b60-999a-4c1e-981e-b68a428c4702\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:25.414165Z\",\"updated_at\":\"2025-07-21T09:59:42.703563Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":75000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"906c0feb-0eb0-4037-94aa-afd4d845b94f\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:27.773573Z\",\"updated_at\":\"2025-07-21T09:59:43.631619Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"ea3ed841-5c79-4b24-a16e-9bd8f9ce7a22\",\"name\":\"mistral/mistral-small-3.2-24b-instruct-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-08-11T16:10:34.758177Z\",\"updated_at\":\"2025-08-21T18:10:43.221207Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":25812437535,\"region\":\"fr-par\"},{\"id\":\"014919c1-00cc-43c2-98f2-4ffd263e6f33\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:41.108667Z\",\"updated_at\":\"2025-07-21T09:57:22.183235Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":141117442445,\"region\":\"fr-par\"},{\"id\":\"bbfeeb62-2428-415d-ad0d-537af9aff946\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:42.762505Z\",\"updated_at\":\"2025-07-21T09:57:23.363918Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679175005,\"region\":\"fr-par\"},{\"id\":\"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3\",\"name\":\"meta/llama-3.1-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:40.045689Z\",\"updated_at\":\"2025-07-21T09:57:28.654817Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132582323,\"region\":\"fr-par\"},{\"id\":\"623a4d27-40c1-4764-a6e2-6ea84d18fd2b\",\"name\":\"qwen/qwen3-coder-30b-a3b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model, excelling in code generation and agentic usage.\",\"created_at\":\"2025-08-11T16:12:00.167204Z\",\"updated_at\":\"2025-08-14T15:10:51.249288Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":31195093698,\"region\":\"fr-par\"},{\"id\":\"a3205fd3-ac4a-47cf-9074-82166d214bac\",\"name\":\"qwen/qwen2.5-coder-32b-instruct:int8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.\",\"created_at\":\"2025-03-27T16:50:12.267422Z\",\"updated_at\":\"2025-07-21T09:57:53.039730Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":35080374444,\"region\":\"fr-par\"},{\"id\":\"739d51ae-4f1e-4193-a4bf-f7380c090d46\",\"name\":\"qwen/qwen3-235b-a22b-instruct-2507:awq\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly capable and versatile language model, optimized for instruction following, logical reasoning, and long-context understanding, with enhanced performance across various domains and preferences.\",\"created_at\":\"2025-07-24T17:35:08.324867Z\",\"updated_at\":\"2025-08-11T13:44:54.877154Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":true,\"max_context_size\":41984},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":4,\"size_bytes\":124094610921,\"region\":\"fr-par\"},{\"id\":\"e7599d92-c1d4-4729-9843-63ca2d5f690d\",\"name\":\"mistral/devstral-small-2505:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Devstral is an agentic LLM for software engineering tasks.\",\"created_at\":\"2025-05-21T16:23:31.620336Z\",\"updated_at\":\"2025-07-21T09:57:30.900075Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":94000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94305992547,\"region\":\"fr-par\"},{\"id\":\"7f3395ee-5bd3-4682-8edb-0c2a21e5583c\",\"name\":\"mistral/magistral-small-2506:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T09:00:40.999454Z\",\"updated_at\":\"2025-07-21T09:57:31.618671Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94309136156,\"region\":\"fr-par\"},{\"id\":\"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8\",\"name\":\"nvidia/llama-3.1-nemotron-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.\",\"created_at\":\"2025-03-27T16:49:51.968791Z\",\"updated_at\":\"2025-07-21T09:57:48.881329Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":15000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679219797,\"region\":\"fr-par\"},{\"id\":\"864e7786-4b86-4f4b-8534-25da1fc46a74\",\"name\":\"allenai/molmo-72b-0924:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\"],\"status\":\"ready\",\"description\":\"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.\",\"created_at\":\"2025-05-13T12:13:50.994Z\",\"updated_at\":\"2025-05-13T13:34:01.318606Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":293245208984,\"region\":\"fr-par\"},{\"id\":\"775cbef7-6527-415d-9e6b-39d574cf39ec\",\"name\":\"meta/llama-3.1-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:37.342054Z\",\"updated_at\":\"2025-07-21T09:57:48.223601Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090504772,\"region\":\"fr-par\"},{\"id\":\"bc10c88e-4d18-4854-8250-77aff4763eca\",\"name\":\"meta/llama-3-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:48:15.818596Z\",\"updated_at\":\"2025-07-21T09:57:27.707608Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132572668,\"region\":\"fr-par\"},{\"id\":\"81006e04-2038-452d-994e-37ed23301280\",\"name\":\"mistral/devstral-small-2505:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient model for code completion and agentic development capabilities supporting up to 128k context window.\",\"created_at\":\"2025-07-18T13:46:47.354953Z\",\"updated_at\":\"2025-07-21T09:57:52.059649Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24953752298,\"region\":\"fr-par\"},{\"id\":\"b5a94646-9390-4ced-acba-9b078e63a794\",\"name\":\"meta/llama-3-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:33.359621Z\",\"updated_at\":\"2025-07-21T09:57:46.335774Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090489355,\"region\":\"fr-par\"},{\"id\":\"126ad0c4-cfde-4b05-924f-f04c6343ccb2\",\"name\":\"meta/llama-3.3-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:42.138410Z\",\"updated_at\":\"2025-07-21T09:57:29.772547Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282254830887,\"region\":\"fr-par\"},{\"id\":\"1678195b-5af6-4c27-8fdc-16aa84c68c34\",\"name\":\"meta/llama-3.3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:50:09.605796Z\",\"updated_at\":\"2025-07-21T10:00:03.783390Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72687332869,\"region\":\"fr-par\"},{\"id\":\"7cbe0417-172a-4601-8940-3b71e4d0c8cb\",\"name\":\"meta/llama-3.1-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:35.312110Z\",\"updated_at\":\"2025-05-09T13:51:52.677798Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":60000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282246710880,\"region\":\"fr-par\"},{\"id\":\"03150ad5-de83-4c74-afe0-3eeeb67d71a3\",\"name\":\"meta/llama-3.1-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:35.836269Z\",\"updated_at\":\"2025-07-21T09:57:47.053289Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13800},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665889083,\"region\":\"fr-par\"},{\"id\":\"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67\",\"name\":\"meta/llama-3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:31.715567Z\",\"updated_at\":\"2025-07-21T09:57:45.596469Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665872089,\"region\":\"fr-par\"},{\"id\":\"cfb8d45f-0861-42e2-a3c2-0223a957321d\",\"name\":\"mistral/magistral-small-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T11:48:08.928974Z\",\"updated_at\":\"2025-07-21T09:57:54.481316Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24951553930,\"region\":\"fr-par\"},{\"id\":\"1e555754-47fb-4dba-a82c-66f3f1fa9294\",\"name\":\"mistral/mistral-small-24b-instruct-2501:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:49:17.458153Z\",\"updated_at\":\"2025-07-21T09:57:32.859222Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94321843451,\"region\":\"fr-par\"},{\"id\":\"7bb28f2c-3719-4d71-9bcb-17db392a7118\",\"name\":\"mistral/mistral-small-24b-instruct-2501:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:50:07.300436Z\",\"updated_at\":\"2025-07-21T09:57:33.402862Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":20000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24938988520,\"region\":\"fr-par\"},{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"},{\"id\":\"fe15cb30-abbe-4e3f-a391-0f2c0a4e713e\",\"name\":\"mistral/pixtral-12b-2409:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-07-29T14:50:25.915554Z\",\"updated_at\":\"2025-07-29T15:07:16.249394Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":85000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844140,\"region\":\"fr-par\"},{\"id\":\"bf6be106-c53d-4b93-bb33-1a4bd4d0b573\",\"name\":\"mistral/mistral-7b-instruct-v0.3:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.\",\"created_at\":\"2025-03-27T16:49:14.593008Z\",\"updated_at\":\"2025-07-21T09:57:32.163053Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":28995471292,\"region\":\"fr-par\"},{\"id\":\"07681325-c743-4796-8b7d-1f0b35d4a8e0\",\"name\":\"mistral/mistral-nemo-instruct-2407:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.\",\"created_at\":\"2025-03-27T16:50:06.301430Z\",\"updated_at\":\"2025-07-21T09:57:49.981056Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":13605604415,\"region\":\"fr-par\"},{\"id\":\"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:50:08.291821Z\",\"updated_at\":\"2025-06-03T15:23:10.521010Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":46970879717,\"region\":\"fr-par\"},{\"id\":\"11ed6599-f460-4e41-b266-87bc9a108fdd\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:49:19.120192Z\",\"updated_at\":\"2025-07-21T09:57:44.508868Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":190483875108,\"region\":\"fr-par\"},{\"id\":\"d58efec4-b667-48e2-8ad8-bcc26c175ae6\",\"name\":\"baai/bge-multilingual-gemma2:fp32\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"embeddings\",\"featured\"],\"status\":\"ready\",\"description\":\"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.\",\"created_at\":\"2025-03-27T16:46:54.314987Z\",\"updated_at\":\"2025-07-30T13:51:53.086101Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]}]}],\"parameter_size_bits\":32,\"size_bytes\":36989461520,\"region\":\"fr-par\"}],\"total_count\":40}"
    headers:
      Content-Length:
      - "66736"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:24 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - f7a4bf09-723c-4081-ac6d-7a92b4bc5f49
    status: 200 OK
    code: 200
    duration: 575.007349ms
- id: 1
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 1688
    body: "{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"}"
    headers:
      Content-Length:
      - "1688"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:24 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - 6f7e81cd-c32b-420b-ab7d-a39bd7133bed
    status: 200 OK
    code: 200
    duration: 26.637228ms
- id: 2
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    form:
      order_by:
      - display_rank_asc
      page_size:
      - "1000"
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 66736
    body: "{\"models\":[{\"id\":\"5c40e594-d40d-452a-991e-5082225155e1\",\"name\":\"google/gemma-3-27b-it:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-04-04T13:11:00.900800Z\",\"updated_at\":\"2025-06-17T09:31:04.122362Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":80000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":54904369444,\"region\":\"fr-par\"},{\"id\":\"4b239330-99eb-4204-af4a-7751756d7c68\",\"name\":\"google/gemma-3-27b-it:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-07-07T19:59:36.326470Z\",\"updated_at\":\"2025-07-07T19:59:45.224797Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":10000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":29313782550,\"region\":\"fr-par\"},{\"id\":\"ed77954f-3a10-49d9-83b8-6b4928c53226\",\"name\":\"openai/gpt-oss-120b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:12.380302Z\",\"updated_at\":\"2025-08-06T09:32:29.360479Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":195764056107,\"region\":\"fr-par\"},{\"id\":\"41c23555-49d1-466d-9008-4656950bc797\",\"name\":\"openai/gpt-oss-20b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:14.686335Z\",\"updated_at\":\"2025-08-06T08:41:10.511923Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":41301481015,\"region\":\"fr-par\"},{\"id\":\"bd2fd3e8-cd89-4b78-b01d-470c78eb4186\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-26T12:45:37.591726Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"59d67ccb-983f-44da-8f86-646cf833d35d\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-25T15:20:50.096009Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"a51ce791-9546-4c28-aa44-24850d84778b\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:11.513249Z\",\"updated_at\":\"2025-07-21T09:57:24.492248Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":39000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":16070465043,\"region\":\"fr-par\"},{\"id\":\"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:14.190404Z\",\"updated_at\":\"2025-07-21T09:57:25.611961Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9093169346,\"region\":\"fr-par\"},{\"id\":\"efcf0b60-999a-4c1e-981e-b68a428c4702\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:25.414165Z\",\"updated_at\":\"2025-07-21T09:59:42.703563Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":75000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"906c0feb-0eb0-4037-94aa-afd4d845b94f\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:27.773573Z\",\"updated_at\":\"2025-07-21T09:59:43.631619Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"ea3ed841-5c79-4b24-a16e-9bd8f9ce7a22\",\"name\":\"mistral/mistral-small-3.2-24b-instruct-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-08-11T16:10:34.758177Z\",\"updated_at\":\"2025-08-21T18:10:43.221207Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":25812437535,\"region\":\"fr-par\"},{\"id\":\"014919c1-00cc-43c2-98f2-4ffd263e6f33\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:41.108667Z\",\"updated_at\":\"2025-07-21T09:57:22.183235Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":141117442445,\"region\":\"fr-par\"},{\"id\":\"bbfeeb62-2428-415d-ad0d-537af9aff946\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:42.762505Z\",\"updated_at\":\"2025-07-21T09:57:23.363918Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679175005,\"region\":\"fr-par\"},{\"id\":\"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3\",\"name\":\"meta/llama-3.1-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:40.045689Z\",\"updated_at\":\"2025-07-21T09:57:28.654817Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132582323,\"region\":\"fr-par\"},{\"id\":\"623a4d27-40c1-4764-a6e2-6ea84d18fd2b\",\"name\":\"qwen/qwen3-coder-30b-a3b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model, excelling in code generation and agentic usage.\",\"created_at\":\"2025-08-11T16:12:00.167204Z\",\"updated_at\":\"2025-08-14T15:10:51.249288Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":31195093698,\"region\":\"fr-par\"},{\"id\":\"a3205fd3-ac4a-47cf-9074-82166d214bac\",\"name\":\"qwen/qwen2.5-coder-32b-instruct:int8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.\",\"created_at\":\"2025-03-27T16:50:12.267422Z\",\"updated_at\":\"2025-07-21T09:57:53.039730Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":35080374444,\"region\":\"fr-par\"},{\"id\":\"739d51ae-4f1e-4193-a4bf-f7380c090d46\",\"name\":\"qwen/qwen3-235b-a22b-instruct-2507:awq\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly capable and versatile language model, optimized for instruction following, logical reasoning, and long-context understanding, with enhanced performance across various domains and preferences.\",\"created_at\":\"2025-07-24T17:35:08.324867Z\",\"updated_at\":\"2025-08-11T13:44:54.877154Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":true,\"max_context_size\":41984},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":4,\"size_bytes\":124094610921,\"region\":\"fr-par\"},{\"id\":\"e7599d92-c1d4-4729-9843-63ca2d5f690d\",\"name\":\"mistral/devstral-small-2505:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Devstral is an agentic LLM for software engineering tasks.\",\"created_at\":\"2025-05-21T16:23:31.620336Z\",\"updated_at\":\"2025-07-21T09:57:30.900075Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":94000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94305992547,\"region\":\"fr-par\"},{\"id\":\"7f3395ee-5bd3-4682-8edb-0c2a21e5583c\",\"name\":\"mistral/magistral-small-2506:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T09:00:40.999454Z\",\"updated_at\":\"2025-07-21T09:57:31.618671Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94309136156,\"region\":\"fr-par\"},{\"id\":\"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8\",\"name\":\"nvidia/llama-3.1-nemotron-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.\",\"created_at\":\"2025-03-27T16:49:51.968791Z\",\"updated_at\":\"2025-07-21T09:57:48.881329Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":15000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679219797,\"region\":\"fr-par\"},{\"id\":\"864e7786-4b86-4f4b-8534-25da1fc46a74\",\"name\":\"allenai/molmo-72b-0924:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\"],\"status\":\"ready\",\"description\":\"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.\",\"created_at\":\"2025-05-13T12:13:50.994Z\",\"updated_at\":\"2025-05-13T13:34:01.318606Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":293245208984,\"region\":\"fr-par\"},{\"id\":\"775cbef7-6527-415d-9e6b-39d574cf39ec\",\"name\":\"meta/llama-3.1-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:37.342054Z\",\"updated_at\":\"2025-07-21T09:57:48.223601Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090504772,\"region\":\"fr-par\"},{\"id\":\"bc10c88e-4d18-4854-8250-77aff4763eca\",\"name\":\"meta/llama-3-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:48:15.818596Z\",\"updated_at\":\"2025-07-21T09:57:27.707608Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132572668,\"region\":\"fr-par\"},{\"id\":\"81006e04-2038-452d-994e-37ed23301280\",\"name\":\"mistral/devstral-small-2505:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient model for code completion and agentic development capabilities supporting up to 128k context window.\",\"created_at\":\"2025-07-18T13:46:47.354953Z\",\"updated_at\":\"2025-07-21T09:57:52.059649Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24953752298,\"region\":\"fr-par\"},{\"id\":\"b5a94646-9390-4ced-acba-9b078e63a794\",\"name\":\"meta/llama-3-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:33.359621Z\",\"updated_at\":\"2025-07-21T09:57:46.335774Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090489355,\"region\":\"fr-par\"},{\"id\":\"126ad0c4-cfde-4b05-924f-f04c6343ccb2\",\"name\":\"meta/llama-3.3-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:42.138410Z\",\"updated_at\":\"2025-07-21T09:57:29.772547Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282254830887,\"region\":\"fr-par\"},{\"id\":\"1678195b-5af6-4c27-8fdc-16aa84c68c34\",\"name\":\"meta/llama-3.3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:50:09.605796Z\",\"updated_at\":\"2025-07-21T10:00:03.783390Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72687332869,\"region\":\"fr-par\"},{\"id\":\"7cbe0417-172a-4601-8940-3b71e4d0c8cb\",\"name\":\"meta/llama-3.1-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:35.312110Z\",\"updated_at\":\"2025-05-09T13:51:52.677798Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":60000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282246710880,\"region\":\"fr-par\"},{\"id\":\"03150ad5-de83-4c74-afe0-3eeeb67d71a3\",\"name\":\"meta/llama-3.1-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:35.836269Z\",\"updated_at\":\"2025-07-21T09:57:47.053289Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13800},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665889083,\"region\":\"fr-par\"},{\"id\":\"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67\",\"name\":\"meta/llama-3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:31.715567Z\",\"updated_at\":\"2025-07-21T09:57:45.596469Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665872089,\"region\":\"fr-par\"},{\"id\":\"cfb8d45f-0861-42e2-a3c2-0223a957321d\",\"name\":\"mistral/magistral-small-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T11:48:08.928974Z\",\"updated_at\":\"2025-07-21T09:57:54.481316Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24951553930,\"region\":\"fr-par\"},{\"id\":\"1e555754-47fb-4dba-a82c-66f3f1fa9294\",\"name\":\"mistral/mistral-small-24b-instruct-2501:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:49:17.458153Z\",\"updated_at\":\"2025-07-21T09:57:32.859222Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94321843451,\"region\":\"fr-par\"},{\"id\":\"7bb28f2c-3719-4d71-9bcb-17db392a7118\",\"name\":\"mistral/mistral-small-24b-instruct-2501:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:50:07.300436Z\",\"updated_at\":\"2025-07-21T09:57:33.402862Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":20000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24938988520,\"region\":\"fr-par\"},{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"},{\"id\":\"fe15cb30-abbe-4e3f-a391-0f2c0a4e713e\",\"name\":\"mistral/pixtral-12b-2409:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-07-29T14:50:25.915554Z\",\"updated_at\":\"2025-07-29T15:07:16.249394Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":85000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844140,\"region\":\"fr-par\"},{\"id\":\"bf6be106-c53d-4b93-bb33-1a4bd4d0b573\",\"name\":\"mistral/mistral-7b-instruct-v0.3:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.\",\"created_at\":\"2025-03-27T16:49:14.593008Z\",\"updated_at\":\"2025-07-21T09:57:32.163053Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":28995471292,\"region\":\"fr-par\"},{\"id\":\"07681325-c743-4796-8b7d-1f0b35d4a8e0\",\"name\":\"mistral/mistral-nemo-instruct-2407:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.\",\"created_at\":\"2025-03-27T16:50:06.301430Z\",\"updated_at\":\"2025-07-21T09:57:49.981056Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":13605604415,\"region\":\"fr-par\"},{\"id\":\"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:50:08.291821Z\",\"updated_at\":\"2025-06-03T15:23:10.521010Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":46970879717,\"region\":\"fr-par\"},{\"id\":\"11ed6599-f460-4e41-b266-87bc9a108fdd\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:49:19.120192Z\",\"updated_at\":\"2025-07-21T09:57:44.508868Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":190483875108,\"region\":\"fr-par\"},{\"id\":\"d58efec4-b667-48e2-8ad8-bcc26c175ae6\",\"name\":\"baai/bge-multilingual-gemma2:fp32\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"embeddings\",\"featured\"],\"status\":\"ready\",\"description\":\"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.\",\"created_at\":\"2025-03-27T16:46:54.314987Z\",\"updated_at\":\"2025-07-30T13:51:53.086101Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]}]}],\"parameter_size_bits\":32,\"size_bytes\":36989461520,\"region\":\"fr-par\"}],\"total_count\":40}"
    headers:
      Content-Length:
      - "66736"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:24 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - 81575503-a622-42b9-b9cf-b78ed4c716bf
    status: 200 OK
    code: 200
    duration: 310.699903ms
- id: 3
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 1688
    body: "{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"}"
    headers:
      Content-Length:
      - "1688"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:24 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - b17b61bc-2a2e-4f57-9556-840593523523
    status: 200 OK
    code: 200
    duration: 33.139934ms
- id: 4
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 1688
    body: "{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"}"
    headers:
      Content-Length:
      - "1688"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:24 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - 781fe0ea-cbf5-49c2-af18-c9802109ee29
    status: 200 OK
    code: 200
    duration: 34.716986ms
- id: 5
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    form:
      order_by:
      - display_rank_asc
      page_size:
      - "1000"
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 71324
    body: "{\"models\":[{\"id\":\"5c40e594-d40d-452a-991e-5082225155e1\",\"name\":\"google/gemma-3-27b-it:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-04-04T13:11:00.900800Z\",\"updated_at\":\"2025-06-17T09:31:04.122362Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":80000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":54904369444,\"region\":\"fr-par\"},{\"id\":\"4b239330-99eb-4204-af4a-7751756d7c68\",\"name\":\"google/gemma-3-27b-it:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-07-07T19:59:36.326470Z\",\"updated_at\":\"2025-07-07T19:59:45.224797Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":10000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":29313782550,\"region\":\"fr-par\"},{\"id\":\"ed77954f-3a10-49d9-83b8-6b4928c53226\",\"name\":\"openai/gpt-oss-120b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:12.380302Z\",\"updated_at\":\"2025-08-06T09:32:29.360479Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":195764056107,\"region\":\"fr-par\"},{\"id\":\"41c23555-49d1-466d-9008-4656950bc797\",\"name\":\"openai/gpt-oss-20b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:14.686335Z\",\"updated_at\":\"2025-08-06T08:41:10.511923Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":41301481015,\"region\":\"fr-par\"},{\"id\":\"f49b28a7-6d32-42a7-845b-3b75952a0500\",\"name\":\"TestAccDataSourceModel_Custom\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-27T16:26:24.219797Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"ce7dadee-a04a-4949-8044-0c7821fe1859\",\"name\":\"TestAccModel_Basic\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-27T16:26:24.190800Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"14269cfa-f6fc-4f73-8ae0-909706e04973\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-27T16:26:24.609814Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"bd2fd3e8-cd89-4b78-b01d-470c78eb4186\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-26T12:45:37.591726Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"59d67ccb-983f-44da-8f86-646cf833d35d\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-25T15:20:50.096009Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"a51ce791-9546-4c28-aa44-24850d84778b\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:11.513249Z\",\"updated_at\":\"2025-07-21T09:57:24.492248Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":39000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":16070465043,\"region\":\"fr-par\"},{\"id\":\"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:14.190404Z\",\"updated_at\":\"2025-07-21T09:57:25.611961Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9093169346,\"region\":\"fr-par\"},{\"id\":\"efcf0b60-999a-4c1e-981e-b68a428c4702\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:25.414165Z\",\"updated_at\":\"2025-07-21T09:59:42.703563Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":75000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"906c0feb-0eb0-4037-94aa-afd4d845b94f\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:27.773573Z\",\"updated_at\":\"2025-07-21T09:59:43.631619Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"ea3ed841-5c79-4b24-a16e-9bd8f9ce7a22\",\"name\":\"mistral/mistral-small-3.2-24b-instruct-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-08-11T16:10:34.758177Z\",\"updated_at\":\"2025-08-21T18:10:43.221207Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":25812437535,\"region\":\"fr-par\"},{\"id\":\"014919c1-00cc-43c2-98f2-4ffd263e6f33\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:41.108667Z\",\"updated_at\":\"2025-07-21T09:57:22.183235Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":141117442445,\"region\":\"fr-par\"},{\"id\":\"bbfeeb62-2428-415d-ad0d-537af9aff946\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:42.762505Z\",\"updated_at\":\"2025-07-21T09:57:23.363918Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679175005,\"region\":\"fr-par\"},{\"id\":\"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3\",\"name\":\"meta/llama-3.1-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:40.045689Z\",\"updated_at\":\"2025-07-21T09:57:28.654817Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132582323,\"region\":\"fr-par\"},{\"id\":\"623a4d27-40c1-4764-a6e2-6ea84d18fd2b\",\"name\":\"qwen/qwen3-coder-30b-a3b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model, excelling in code generation and agentic usage.\",\"created_at\":\"2025-08-11T16:12:00.167204Z\",\"updated_at\":\"2025-08-14T15:10:51.249288Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":31195093698,\"region\":\"fr-par\"},{\"id\":\"a3205fd3-ac4a-47cf-9074-82166d214bac\",\"name\":\"qwen/qwen2.5-coder-32b-instruct:int8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.\",\"created_at\":\"2025-03-27T16:50:12.267422Z\",\"updated_at\":\"2025-07-21T09:57:53.039730Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":35080374444,\"region\":\"fr-par\"},{\"id\":\"739d51ae-4f1e-4193-a4bf-f7380c090d46\",\"name\":\"qwen/qwen3-235b-a22b-instruct-2507:awq\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly capable and versatile language model, optimized for instruction following, logical reasoning, and long-context understanding, with enhanced performance across various domains and preferences.\",\"created_at\":\"2025-07-24T17:35:08.324867Z\",\"updated_at\":\"2025-08-11T13:44:54.877154Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":true,\"max_context_size\":41984},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":4,\"size_bytes\":124094610921,\"region\":\"fr-par\"},{\"id\":\"e7599d92-c1d4-4729-9843-63ca2d5f690d\",\"name\":\"mistral/devstral-small-2505:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Devstral is an agentic LLM for software engineering tasks.\",\"created_at\":\"2025-05-21T16:23:31.620336Z\",\"updated_at\":\"2025-07-21T09:57:30.900075Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":94000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94305992547,\"region\":\"fr-par\"},{\"id\":\"7f3395ee-5bd3-4682-8edb-0c2a21e5583c\",\"name\":\"mistral/magistral-small-2506:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T09:00:40.999454Z\",\"updated_at\":\"2025-07-21T09:57:31.618671Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94309136156,\"region\":\"fr-par\"},{\"id\":\"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8\",\"name\":\"nvidia/llama-3.1-nemotron-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.\",\"created_at\":\"2025-03-27T16:49:51.968791Z\",\"updated_at\":\"2025-07-21T09:57:48.881329Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":15000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679219797,\"region\":\"fr-par\"},{\"id\":\"864e7786-4b86-4f4b-8534-25da1fc46a74\",\"name\":\"allenai/molmo-72b-0924:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\"],\"status\":\"ready\",\"description\":\"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.\",\"created_at\":\"2025-05-13T12:13:50.994Z\",\"updated_at\":\"2025-05-13T13:34:01.318606Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":293245208984,\"region\":\"fr-par\"},{\"id\":\"775cbef7-6527-415d-9e6b-39d574cf39ec\",\"name\":\"meta/llama-3.1-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:37.342054Z\",\"updated_at\":\"2025-07-21T09:57:48.223601Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090504772,\"region\":\"fr-par\"},{\"id\":\"bc10c88e-4d18-4854-8250-77aff4763eca\",\"name\":\"meta/llama-3-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:48:15.818596Z\",\"updated_at\":\"2025-07-21T09:57:27.707608Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132572668,\"region\":\"fr-par\"},{\"id\":\"81006e04-2038-452d-994e-37ed23301280\",\"name\":\"mistral/devstral-small-2505:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient model for code completion and agentic development capabilities supporting up to 128k context window.\",\"created_at\":\"2025-07-18T13:46:47.354953Z\",\"updated_at\":\"2025-07-21T09:57:52.059649Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24953752298,\"region\":\"fr-par\"},{\"id\":\"b5a94646-9390-4ced-acba-9b078e63a794\",\"name\":\"meta/llama-3-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:33.359621Z\",\"updated_at\":\"2025-07-21T09:57:46.335774Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090489355,\"region\":\"fr-par\"},{\"id\":\"126ad0c4-cfde-4b05-924f-f04c6343ccb2\",\"name\":\"meta/llama-3.3-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:42.138410Z\",\"updated_at\":\"2025-07-21T09:57:29.772547Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282254830887,\"region\":\"fr-par\"},{\"id\":\"1678195b-5af6-4c27-8fdc-16aa84c68c34\",\"name\":\"meta/llama-3.3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:50:09.605796Z\",\"updated_at\":\"2025-07-21T10:00:03.783390Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72687332869,\"region\":\"fr-par\"},{\"id\":\"7cbe0417-172a-4601-8940-3b71e4d0c8cb\",\"name\":\"meta/llama-3.1-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:35.312110Z\",\"updated_at\":\"2025-05-09T13:51:52.677798Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":60000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282246710880,\"region\":\"fr-par\"},{\"id\":\"03150ad5-de83-4c74-afe0-3eeeb67d71a3\",\"name\":\"meta/llama-3.1-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:35.836269Z\",\"updated_at\":\"2025-07-21T09:57:47.053289Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13800},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665889083,\"region\":\"fr-par\"},{\"id\":\"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67\",\"name\":\"meta/llama-3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:31.715567Z\",\"updated_at\":\"2025-07-21T09:57:45.596469Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665872089,\"region\":\"fr-par\"},{\"id\":\"cfb8d45f-0861-42e2-a3c2-0223a957321d\",\"name\":\"mistral/magistral-small-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T11:48:08.928974Z\",\"updated_at\":\"2025-07-21T09:57:54.481316Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24951553930,\"region\":\"fr-par\"},{\"id\":\"1e555754-47fb-4dba-a82c-66f3f1fa9294\",\"name\":\"mistral/mistral-small-24b-instruct-2501:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:49:17.458153Z\",\"updated_at\":\"2025-07-21T09:57:32.859222Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94321843451,\"region\":\"fr-par\"},{\"id\":\"7bb28f2c-3719-4d71-9bcb-17db392a7118\",\"name\":\"mistral/mistral-small-24b-instruct-2501:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:50:07.300436Z\",\"updated_at\":\"2025-07-21T09:57:33.402862Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":20000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24938988520,\"region\":\"fr-par\"},{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"},{\"id\":\"fe15cb30-abbe-4e3f-a391-0f2c0a4e713e\",\"name\":\"mistral/pixtral-12b-2409:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-07-29T14:50:25.915554Z\",\"updated_at\":\"2025-07-29T15:07:16.249394Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":85000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844140,\"region\":\"fr-par\"},{\"id\":\"bf6be106-c53d-4b93-bb33-1a4bd4d0b573\",\"name\":\"mistral/mistral-7b-instruct-v0.3:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.\",\"created_at\":\"2025-03-27T16:49:14.593008Z\",\"updated_at\":\"2025-07-21T09:57:32.163053Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":28995471292,\"region\":\"fr-par\"},{\"id\":\"07681325-c743-4796-8b7d-1f0b35d4a8e0\",\"name\":\"mistral/mistral-nemo-instruct-2407:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.\",\"created_at\":\"2025-03-27T16:50:06.301430Z\",\"updated_at\":\"2025-07-21T09:57:49.981056Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":13605604415,\"region\":\"fr-par\"},{\"id\":\"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:50:08.291821Z\",\"updated_at\":\"2025-06-03T15:23:10.521010Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":46970879717,\"region\":\"fr-par\"},{\"id\":\"11ed6599-f460-4e41-b266-87bc9a108fdd\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:49:19.120192Z\",\"updated_at\":\"2025-07-21T09:57:44.508868Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":190483875108,\"region\":\"fr-par\"},{\"id\":\"d58efec4-b667-48e2-8ad8-bcc26c175ae6\",\"name\":\"baai/bge-multilingual-gemma2:fp32\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"embeddings\",\"featured\"],\"status\":\"ready\",\"description\":\"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.\",\"created_at\":\"2025-03-27T16:46:54.314987Z\",\"updated_at\":\"2025-07-30T13:51:53.086101Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]}]}],\"parameter_size_bits\":32,\"size_bytes\":36989461520,\"region\":\"fr-par\"}],\"total_count\":43}"
    headers:
      Content-Length:
      - "71324"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:25 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - d11fea0b-dad8-4b30-bfc8-f80bf4334ea2
    status: 200 OK
    code: 200
    duration: 346.776594ms
- id: 6
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 1688
    body: "{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"}"
    headers:
      Content-Length:
      - "1688"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:25 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - fba273a4-7ced-4941-9edd-ebe075c4a9cb
    status: 200 OK
    code: 200
    duration: 30.484847ms
- id: 7
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    form:
      order_by:
      - display_rank_asc
      page_size:
      - "1000"
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 69803
    body: "{\"models\":[{\"id\":\"5c40e594-d40d-452a-991e-5082225155e1\",\"name\":\"google/gemma-3-27b-it:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-04-04T13:11:00.900800Z\",\"updated_at\":\"2025-06-17T09:31:04.122362Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":80000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":54904369444,\"region\":\"fr-par\"},{\"id\":\"4b239330-99eb-4204-af4a-7751756d7c68\",\"name\":\"google/gemma-3-27b-it:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-07-07T19:59:36.326470Z\",\"updated_at\":\"2025-07-07T19:59:45.224797Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":10000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":29313782550,\"region\":\"fr-par\"},{\"id\":\"ed77954f-3a10-49d9-83b8-6b4928c53226\",\"name\":\"openai/gpt-oss-120b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:12.380302Z\",\"updated_at\":\"2025-08-06T09:32:29.360479Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":195764056107,\"region\":\"fr-par\"},{\"id\":\"41c23555-49d1-466d-9008-4656950bc797\",\"name\":\"openai/gpt-oss-20b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:14.686335Z\",\"updated_at\":\"2025-08-06T08:41:10.511923Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":41301481015,\"region\":\"fr-par\"},{\"id\":\"f49b28a7-6d32-42a7-845b-3b75952a0500\",\"name\":\"TestAccDataSourceModel_Custom\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-27T16:26:24.219797Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"59d67ccb-983f-44da-8f86-646cf833d35d\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-25T15:20:50.096009Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"14269cfa-f6fc-4f73-8ae0-909706e04973\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-27T16:26:24.609814Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"bd2fd3e8-cd89-4b78-b01d-470c78eb4186\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-26T12:45:37.591726Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"a51ce791-9546-4c28-aa44-24850d84778b\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:11.513249Z\",\"updated_at\":\"2025-07-21T09:57:24.492248Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":39000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":16070465043,\"region\":\"fr-par\"},{\"id\":\"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:14.190404Z\",\"updated_at\":\"2025-07-21T09:57:25.611961Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9093169346,\"region\":\"fr-par\"},{\"id\":\"efcf0b60-999a-4c1e-981e-b68a428c4702\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:25.414165Z\",\"updated_at\":\"2025-07-21T09:59:42.703563Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":75000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"906c0feb-0eb0-4037-94aa-afd4d845b94f\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:27.773573Z\",\"updated_at\":\"2025-07-21T09:59:43.631619Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"ea3ed841-5c79-4b24-a16e-9bd8f9ce7a22\",\"name\":\"mistral/mistral-small-3.2-24b-instruct-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-08-11T16:10:34.758177Z\",\"updated_at\":\"2025-08-21T18:10:43.221207Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":25812437535,\"region\":\"fr-par\"},{\"id\":\"014919c1-00cc-43c2-98f2-4ffd263e6f33\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:41.108667Z\",\"updated_at\":\"2025-07-21T09:57:22.183235Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":141117442445,\"region\":\"fr-par\"},{\"id\":\"bbfeeb62-2428-415d-ad0d-537af9aff946\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:42.762505Z\",\"updated_at\":\"2025-07-21T09:57:23.363918Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679175005,\"region\":\"fr-par\"},{\"id\":\"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3\",\"name\":\"meta/llama-3.1-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:40.045689Z\",\"updated_at\":\"2025-07-21T09:57:28.654817Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132582323,\"region\":\"fr-par\"},{\"id\":\"623a4d27-40c1-4764-a6e2-6ea84d18fd2b\",\"name\":\"qwen/qwen3-coder-30b-a3b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model, excelling in code generation and agentic usage.\",\"created_at\":\"2025-08-11T16:12:00.167204Z\",\"updated_at\":\"2025-08-14T15:10:51.249288Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":31195093698,\"region\":\"fr-par\"},{\"id\":\"a3205fd3-ac4a-47cf-9074-82166d214bac\",\"name\":\"qwen/qwen2.5-coder-32b-instruct:int8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.\",\"created_at\":\"2025-03-27T16:50:12.267422Z\",\"updated_at\":\"2025-07-21T09:57:53.039730Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":35080374444,\"region\":\"fr-par\"},{\"id\":\"739d51ae-4f1e-4193-a4bf-f7380c090d46\",\"name\":\"qwen/qwen3-235b-a22b-instruct-2507:awq\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly capable and versatile language model, optimized for instruction following, logical reasoning, and long-context understanding, with enhanced performance across various domains and preferences.\",\"created_at\":\"2025-07-24T17:35:08.324867Z\",\"updated_at\":\"2025-08-11T13:44:54.877154Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":true,\"max_context_size\":41984},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":4,\"size_bytes\":124094610921,\"region\":\"fr-par\"},{\"id\":\"e7599d92-c1d4-4729-9843-63ca2d5f690d\",\"name\":\"mistral/devstral-small-2505:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Devstral is an agentic LLM for software engineering tasks.\",\"created_at\":\"2025-05-21T16:23:31.620336Z\",\"updated_at\":\"2025-07-21T09:57:30.900075Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":94000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94305992547,\"region\":\"fr-par\"},{\"id\":\"7f3395ee-5bd3-4682-8edb-0c2a21e5583c\",\"name\":\"mistral/magistral-small-2506:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T09:00:40.999454Z\",\"updated_at\":\"2025-07-21T09:57:31.618671Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94309136156,\"region\":\"fr-par\"},{\"id\":\"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8\",\"name\":\"nvidia/llama-3.1-nemotron-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.\",\"created_at\":\"2025-03-27T16:49:51.968791Z\",\"updated_at\":\"2025-07-21T09:57:48.881329Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":15000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679219797,\"region\":\"fr-par\"},{\"id\":\"864e7786-4b86-4f4b-8534-25da1fc46a74\",\"name\":\"allenai/molmo-72b-0924:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\"],\"status\":\"ready\",\"description\":\"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.\",\"created_at\":\"2025-05-13T12:13:50.994Z\",\"updated_at\":\"2025-05-13T13:34:01.318606Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":293245208984,\"region\":\"fr-par\"},{\"id\":\"775cbef7-6527-415d-9e6b-39d574cf39ec\",\"name\":\"meta/llama-3.1-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:37.342054Z\",\"updated_at\":\"2025-07-21T09:57:48.223601Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090504772,\"region\":\"fr-par\"},{\"id\":\"bc10c88e-4d18-4854-8250-77aff4763eca\",\"name\":\"meta/llama-3-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:48:15.818596Z\",\"updated_at\":\"2025-07-21T09:57:27.707608Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132572668,\"region\":\"fr-par\"},{\"id\":\"81006e04-2038-452d-994e-37ed23301280\",\"name\":\"mistral/devstral-small-2505:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient model for code completion and agentic development capabilities supporting up to 128k context window.\",\"created_at\":\"2025-07-18T13:46:47.354953Z\",\"updated_at\":\"2025-07-21T09:57:52.059649Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24953752298,\"region\":\"fr-par\"},{\"id\":\"b5a94646-9390-4ced-acba-9b078e63a794\",\"name\":\"meta/llama-3-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:33.359621Z\",\"updated_at\":\"2025-07-21T09:57:46.335774Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090489355,\"region\":\"fr-par\"},{\"id\":\"126ad0c4-cfde-4b05-924f-f04c6343ccb2\",\"name\":\"meta/llama-3.3-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:42.138410Z\",\"updated_at\":\"2025-07-21T09:57:29.772547Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282254830887,\"region\":\"fr-par\"},{\"id\":\"1678195b-5af6-4c27-8fdc-16aa84c68c34\",\"name\":\"meta/llama-3.3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:50:09.605796Z\",\"updated_at\":\"2025-07-21T10:00:03.783390Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72687332869,\"region\":\"fr-par\"},{\"id\":\"7cbe0417-172a-4601-8940-3b71e4d0c8cb\",\"name\":\"meta/llama-3.1-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:35.312110Z\",\"updated_at\":\"2025-05-09T13:51:52.677798Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":60000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282246710880,\"region\":\"fr-par\"},{\"id\":\"03150ad5-de83-4c74-afe0-3eeeb67d71a3\",\"name\":\"meta/llama-3.1-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:35.836269Z\",\"updated_at\":\"2025-07-21T09:57:47.053289Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13800},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665889083,\"region\":\"fr-par\"},{\"id\":\"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67\",\"name\":\"meta/llama-3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:31.715567Z\",\"updated_at\":\"2025-07-21T09:57:45.596469Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665872089,\"region\":\"fr-par\"},{\"id\":\"cfb8d45f-0861-42e2-a3c2-0223a957321d\",\"name\":\"mistral/magistral-small-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T11:48:08.928974Z\",\"updated_at\":\"2025-07-21T09:57:54.481316Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24951553930,\"region\":\"fr-par\"},{\"id\":\"1e555754-47fb-4dba-a82c-66f3f1fa9294\",\"name\":\"mistral/mistral-small-24b-instruct-2501:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:49:17.458153Z\",\"updated_at\":\"2025-07-21T09:57:32.859222Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94321843451,\"region\":\"fr-par\"},{\"id\":\"7bb28f2c-3719-4d71-9bcb-17db392a7118\",\"name\":\"mistral/mistral-small-24b-instruct-2501:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:50:07.300436Z\",\"updated_at\":\"2025-07-21T09:57:33.402862Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":20000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24938988520,\"region\":\"fr-par\"},{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"},{\"id\":\"fe15cb30-abbe-4e3f-a391-0f2c0a4e713e\",\"name\":\"mistral/pixtral-12b-2409:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-07-29T14:50:25.915554Z\",\"updated_at\":\"2025-07-29T15:07:16.249394Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":85000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844140,\"region\":\"fr-par\"},{\"id\":\"bf6be106-c53d-4b93-bb33-1a4bd4d0b573\",\"name\":\"mistral/mistral-7b-instruct-v0.3:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.\",\"created_at\":\"2025-03-27T16:49:14.593008Z\",\"updated_at\":\"2025-07-21T09:57:32.163053Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":28995471292,\"region\":\"fr-par\"},{\"id\":\"07681325-c743-4796-8b7d-1f0b35d4a8e0\",\"name\":\"mistral/mistral-nemo-instruct-2407:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.\",\"created_at\":\"2025-03-27T16:50:06.301430Z\",\"updated_at\":\"2025-07-21T09:57:49.981056Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":13605604415,\"region\":\"fr-par\"},{\"id\":\"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:50:08.291821Z\",\"updated_at\":\"2025-06-03T15:23:10.521010Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":46970879717,\"region\":\"fr-par\"},{\"id\":\"11ed6599-f460-4e41-b266-87bc9a108fdd\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:49:19.120192Z\",\"updated_at\":\"2025-07-21T09:57:44.508868Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":190483875108,\"region\":\"fr-par\"},{\"id\":\"d58efec4-b667-48e2-8ad8-bcc26c175ae6\",\"name\":\"baai/bge-multilingual-gemma2:fp32\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"embeddings\",\"featured\"],\"status\":\"ready\",\"description\":\"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.\",\"created_at\":\"2025-03-27T16:46:54.314987Z\",\"updated_at\":\"2025-07-30T13:51:53.086101Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]}]}],\"parameter_size_bits\":32,\"size_bytes\":36989461520,\"region\":\"fr-par\"}],\"total_count\":42}"
    headers:
      Content-Length:
      - "69803"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:25 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - 30ea39d6-558e-492a-b731-84b71c4747ae
    status: 200 OK
    code: 200
    duration: 399.019694ms
- id: 8
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 1688
    body: "{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"}"
    headers:
      Content-Length:
      - "1688"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:25 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - b8845f61-69b3-4229-a33b-1c128eb18ad2
    status: 200 OK
    code: 200
    duration: 31.045118ms
- id: 9
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    form:
      order_by:
      - display_rank_asc
      page_size:
      - "1000"
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 69803
    body: "{\"models\":[{\"id\":\"5c40e594-d40d-452a-991e-5082225155e1\",\"name\":\"google/gemma-3-27b-it:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-04-04T13:11:00.900800Z\",\"updated_at\":\"2025-06-17T09:31:04.122362Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":80000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":54904369444,\"region\":\"fr-par\"},{\"id\":\"4b239330-99eb-4204-af4a-7751756d7c68\",\"name\":\"google/gemma-3-27b-it:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Multimodal model for text generation an image understanding supporting up to 128k context window.\",\"created_at\":\"2025-07-07T19:59:36.326470Z\",\"updated_at\":\"2025-07-07T19:59:45.224797Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":10000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":29313782550,\"region\":\"fr-par\"},{\"id\":\"ed77954f-3a10-49d9-83b8-6b4928c53226\",\"name\":\"openai/gpt-oss-120b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:12.380302Z\",\"updated_at\":\"2025-08-06T09:32:29.360479Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":195764056107,\"region\":\"fr-par\"},{\"id\":\"41c23555-49d1-466d-9008-4656950bc797\",\"name\":\"openai/gpt-oss-20b:fp4\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-06T08:34:14.686335Z\",\"updated_at\":\"2025-08-06T08:41:10.511923Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":41301481015,\"region\":\"fr-par\"},{\"id\":\"f49b28a7-6d32-42a7-845b-3b75952a0500\",\"name\":\"TestAccDataSourceModel_Custom\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-27T16:26:24.219797Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"59d67ccb-983f-44da-8f86-646cf833d35d\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-25T15:20:50.096009Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"14269cfa-f6fc-4f73-8ae0-909706e04973\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-27T16:26:24.609814Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"bd2fd3e8-cd89-4b78-b01d-470c78eb4186\",\"name\":\"TestAccModel_DeployModelOnServer\",\"project_id\":\"fa1e3217-dc80-42ac-85c3-3f034b78b552\",\"tags\":[\"custom\"],\"status\":\"ready\",\"description\":\"\",\"created_at\":\"2025-08-26T12:45:37.591726Z\",\"updated_at\":null,\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":18615},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":32,\"size_bytes\":59091725385,\"region\":\"fr-par\"},{\"id\":\"a51ce791-9546-4c28-aa44-24850d84778b\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:11.513249Z\",\"updated_at\":\"2025-07-21T09:57:24.492248Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":39000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":16070465043,\"region\":\"fr-par\"},{\"id\":\"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f\",\"name\":\"deepseek/deepseek-r1-distill-llama-8b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:48:14.190404Z\",\"updated_at\":\"2025-07-21T09:57:25.611961Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":90000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9093169346,\"region\":\"fr-par\"},{\"id\":\"efcf0b60-999a-4c1e-981e-b68a428c4702\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:25.414165Z\",\"updated_at\":\"2025-07-21T09:59:42.703563Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":75000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"906c0feb-0eb0-4037-94aa-afd4d845b94f\",\"name\":\"mistral/mistral-small-3.1-24b-instruct-2503:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-04-04T15:51:27.773573Z\",\"updated_at\":\"2025-07-21T09:59:43.631619Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":96077777613,\"region\":\"fr-par\"},{\"id\":\"ea3ed841-5c79-4b24-a16e-9bd8f9ce7a22\",\"name\":\"mistral/mistral-small-3.2-24b-instruct-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.\",\"created_at\":\"2025-08-11T16:10:34.758177Z\",\"updated_at\":\"2025-08-21T18:10:43.221207Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":25812437535,\"region\":\"fr-par\"},{\"id\":\"014919c1-00cc-43c2-98f2-4ffd263e6f33\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:41.108667Z\",\"updated_at\":\"2025-07-21T09:57:22.183235Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":141117442445,\"region\":\"fr-par\"},{\"id\":\"bbfeeb62-2428-415d-ad0d-537af9aff946\",\"name\":\"deepseek/deepseek-r1-distill-llama-70b:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.\",\"created_at\":\"2025-03-27T16:47:42.762505Z\",\"updated_at\":\"2025-07-21T09:57:23.363918Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679175005,\"region\":\"fr-par\"},{\"id\":\"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3\",\"name\":\"meta/llama-3.1-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:40.045689Z\",\"updated_at\":\"2025-07-21T09:57:28.654817Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132582323,\"region\":\"fr-par\"},{\"id\":\"623a4d27-40c1-4764-a6e2-6ea84d18fd2b\",\"name\":\"qwen/qwen3-coder-30b-a3b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model, excelling in code generation and agentic usage.\",\"created_at\":\"2025-08-11T16:12:00.167204Z\",\"updated_at\":\"2025-08-14T15:10:51.249288Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":31195093698,\"region\":\"fr-par\"},{\"id\":\"a3205fd3-ac4a-47cf-9074-82166d214bac\",\"name\":\"qwen/qwen2.5-coder-32b-instruct:int8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.\",\"created_at\":\"2025-03-27T16:50:12.267422Z\",\"updated_at\":\"2025-07-21T09:57:53.039730Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":35080374444,\"region\":\"fr-par\"},{\"id\":\"739d51ae-4f1e-4193-a4bf-f7380c090d46\",\"name\":\"qwen/qwen3-235b-a22b-instruct-2507:awq\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly capable and versatile language model, optimized for instruction following, logical reasoning, and long-context understanding, with enhanced performance across various domains and preferences.\",\"created_at\":\"2025-07-24T17:35:08.324867Z\",\"updated_at\":\"2025-08-11T13:44:54.877154Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":true,\"max_context_size\":41984},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":4,\"size_bytes\":124094610921,\"region\":\"fr-par\"},{\"id\":\"e7599d92-c1d4-4729-9843-63ca2d5f690d\",\"name\":\"mistral/devstral-small-2505:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Devstral is an agentic LLM for software engineering tasks.\",\"created_at\":\"2025-05-21T16:23:31.620336Z\",\"updated_at\":\"2025-07-21T09:57:30.900075Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":94000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94305992547,\"region\":\"fr-par\"},{\"id\":\"7f3395ee-5bd3-4682-8edb-0c2a21e5583c\",\"name\":\"mistral/magistral-small-2506:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T09:00:40.999454Z\",\"updated_at\":\"2025-07-21T09:57:31.618671Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":40960},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94309136156,\"region\":\"fr-par\"},{\"id\":\"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8\",\"name\":\"nvidia/llama-3.1-nemotron-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.\",\"created_at\":\"2025-03-27T16:49:51.968791Z\",\"updated_at\":\"2025-07-21T09:57:48.881329Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":15000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72679219797,\"region\":\"fr-par\"},{\"id\":\"864e7786-4b86-4f4b-8534-25da1fc46a74\",\"name\":\"allenai/molmo-72b-0924:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"vision\"],\"status\":\"ready\",\"description\":\"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.\",\"created_at\":\"2025-05-13T12:13:50.994Z\",\"updated_at\":\"2025-05-13T13:34:01.318606Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":293245208984,\"region\":\"fr-par\"},{\"id\":\"775cbef7-6527-415d-9e6b-39d574cf39ec\",\"name\":\"meta/llama-3.1-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"Efficient 8B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:37.342054Z\",\"updated_at\":\"2025-07-21T09:57:48.223601Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":93000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090504772,\"region\":\"fr-par\"},{\"id\":\"bc10c88e-4d18-4854-8250-77aff4763eca\",\"name\":\"meta/llama-3-8b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:48:15.818596Z\",\"updated_at\":\"2025-07-21T09:57:27.707608Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":32132572668,\"region\":\"fr-par\"},{\"id\":\"81006e04-2038-452d-994e-37ed23301280\",\"name\":\"mistral/devstral-small-2505:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"code\",\"featured\"],\"status\":\"ready\",\"description\":\"Highly efficient model for code completion and agentic development capabilities supporting up to 128k context window.\",\"created_at\":\"2025-07-18T13:46:47.354953Z\",\"updated_at\":\"2025-07-21T09:57:52.059649Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24953752298,\"region\":\"fr-par\"},{\"id\":\"b5a94646-9390-4ced-acba-9b078e63a794\",\"name\":\"meta/llama-3-8b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:33.359621Z\",\"updated_at\":\"2025-07-21T09:57:46.335774Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":9090489355,\"region\":\"fr-par\"},{\"id\":\"126ad0c4-cfde-4b05-924f-f04c6343ccb2\",\"name\":\"meta/llama-3.3-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:42.138410Z\",\"updated_at\":\"2025-07-21T09:57:29.772547Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":45000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282254830887,\"region\":\"fr-par\"},{\"id\":\"1678195b-5af6-4c27-8fdc-16aa84c68c34\",\"name\":\"meta/llama-3.3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:50:09.605796Z\",\"updated_at\":\"2025-07-21T10:00:03.783390Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72687332869,\"region\":\"fr-par\"},{\"id\":\"7cbe0417-172a-4601-8940-3b71e4d0c8cb\",\"name\":\"meta/llama-3.1-70b-instruct:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:48:35.312110Z\",\"updated_at\":\"2025-05-09T13:51:52.677798Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":60000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":282246710880,\"region\":\"fr-par\"},{\"id\":\"03150ad5-de83-4c74-afe0-3eeeb67d71a3\",\"name\":\"meta/llama-3.1-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Efficient 70B-param model by Meta, optimized for multilingual dialogue.\",\"created_at\":\"2025-03-27T16:49:35.836269Z\",\"updated_at\":\"2025-07-21T09:57:47.053289Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":13800},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":131072},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665889083,\"region\":\"fr-par\"},{\"id\":\"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67\",\"name\":\"meta/llama-3-70b-instruct:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.\",\"created_at\":\"2025-03-27T16:49:31.715567Z\",\"updated_at\":\"2025-07-21T09:57:45.596469Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":8192},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":72665872089,\"region\":\"fr-par\"},{\"id\":\"cfb8d45f-0861-42e2-a3c2-0223a957321d\",\"name\":\"mistral/magistral-small-2506:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Magistral Small is a mid-size reasoning LLM for general purpose tasks.\",\"created_at\":\"2025-06-11T11:48:08.928974Z\",\"updated_at\":\"2025-07-21T09:57:54.481316Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24951553930,\"region\":\"fr-par\"},{\"id\":\"1e555754-47fb-4dba-a82c-66f3f1fa9294\",\"name\":\"mistral/mistral-small-24b-instruct-2501:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:49:17.458153Z\",\"updated_at\":\"2025-07-21T09:57:32.859222Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":94321843451,\"region\":\"fr-par\"},{\"id\":\"7bb28f2c-3719-4d71-9bcb-17db392a7118\",\"name\":\"mistral/mistral-small-24b-instruct-2501:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.\",\"created_at\":\"2025-03-27T16:50:07.300436Z\",\"updated_at\":\"2025-07-21T09:57:33.402862Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":20000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":24938988520,\"region\":\"fr-par\"},{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"},{\"id\":\"fe15cb30-abbe-4e3f-a391-0f2c0a4e713e\",\"name\":\"mistral/pixtral-12b-2409:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-07-29T14:50:25.915554Z\",\"updated_at\":\"2025-07-29T15:07:16.249394Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":85000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844140,\"region\":\"fr-par\"},{\"id\":\"bf6be106-c53d-4b93-bb33-1a4bd4d0b573\",\"name\":\"mistral/mistral-7b-instruct-v0.3:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.\",\"created_at\":\"2025-03-27T16:49:14.593008Z\",\"updated_at\":\"2025-07-21T09:57:32.163053Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":28995471292,\"region\":\"fr-par\"},{\"id\":\"07681325-c743-4796-8b7d-1f0b35d4a8e0\",\"name\":\"mistral/mistral-nemo-instruct-2407:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.\",\"created_at\":\"2025-03-27T16:50:06.301430Z\",\"updated_at\":\"2025-07-21T09:57:49.981056Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":13605604415,\"region\":\"fr-par\"},{\"id\":\"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:fp8\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:50:08.291821Z\",\"updated_at\":\"2025-06-03T15:23:10.521010Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":8,\"size_bytes\":46970879717,\"region\":\"fr-par\"},{\"id\":\"11ed6599-f460-4e41-b266-87bc9a108fdd\",\"name\":\"mistral/mixtral-8x7b-instruct-v0.1:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"instruct\",\"chat\"],\"status\":\"ready\",\"description\":\"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.\",\"created_at\":\"2025-03-27T16:49:19.120192Z\",\"updated_at\":\"2025-07-21T09:57:44.508868Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":32768},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":190483875108,\"region\":\"fr-par\"},{\"id\":\"d58efec4-b667-48e2-8ad8-bcc26c175ae6\",\"name\":\"baai/bge-multilingual-gemma2:fp32\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"embeddings\",\"featured\"],\"status\":\"ready\",\"description\":\"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.\",\"created_at\":\"2025-03-27T16:46:54.314987Z\",\"updated_at\":\"2025-07-30T13:51:53.086101Z\",\"has_eula\":true,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":true,\"max_context_size\":8192}]}]}],\"parameter_size_bits\":32,\"size_bytes\":36989461520,\"region\":\"fr-par\"}],\"total_count\":42}"
    headers:
      Content-Length:
      - "69803"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:26 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - b2aed46a-1eb2-43e2-92d4-8cb067ceb490
    status: 200 OK
    code: 200
    duration: 372.284322ms
- id: 10
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 0
    host: api.scaleway.com
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; linux; amd64) terraform-provider/develop terraform/terraform-tests
    url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
    method: GET
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 1688
    body: "{\"id\":\"1999f4f5-f038-4039-94ba-11a851917df5\",\"name\":\"mistral/pixtral-12b-2409:bf16\",\"project_id\":\"00000000-0000-0000-0000-000000000000\",\"tags\":[\"vision\",\"chat\",\"featured\"],\"status\":\"ready\",\"description\":\"Vision language model able to analyze images and offer insights without compromising on instruction following.\",\"created_at\":\"2025-04-15T10:51:31.291792Z\",\"updated_at\":\"2025-07-28T15:01:27.662589Z\",\"has_eula\":false,\"nodes_support\":[{\"nodes\":[{\"node_type_name\":\"L4\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"L40S\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":50000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]},{\"node_type_name\":\"H100-2\",\"quantizations\":[{\"quantization_bits\":4,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":8,\"allowed\":false,\"max_context_size\":0},{\"quantization_bits\":16,\"allowed\":true,\"max_context_size\":128000},{\"quantization_bits\":32,\"allowed\":false,\"max_context_size\":0}]}]}],\"parameter_size_bits\":16,\"size_bytes\":25384844091,\"region\":\"fr-par\"}"
    headers:
      Content-Length:
      - "1688"
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Aug 2025 16:26:26 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge02)
      X-Request-Id:
      - b7d8e26a-3a3c-4526-b7fe-a8b901aaa0a3
    status: 200 OK
    code: 200
    duration: 32.771452ms
