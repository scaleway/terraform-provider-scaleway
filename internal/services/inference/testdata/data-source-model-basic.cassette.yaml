---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:52 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 157a83bd-c2b3-44ba-ad5f-a67fa0ab62cc
        status: 200 OK
        code: 200
        duration: 293.412084ms
    - id: 1
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1753
        uncompressed: false
        body: '{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"}'
        headers:
            Content-Length:
                - "1753"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:52 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 7080b849-e80d-4a68-af90-2482d9cd09f7
        status: 200 OK
        code: 200
        duration: 149.1175ms
    - id: 2
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:53 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 2adc88fc-12b5-494e-9fd3-04a32691cacb
        status: 200 OK
        code: 200
        duration: 216.725541ms
    - id: 3
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1753
        uncompressed: false
        body: '{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"}'
        headers:
            Content-Length:
                - "1753"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:53 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 6d9e219a-af3c-450c-adb6-e72749365dfe
        status: 200 OK
        code: 200
        duration: 41.010625ms
    - id: 4
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1753
        uncompressed: false
        body: '{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"}'
        headers:
            Content-Length:
                - "1753"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:53 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - bb92cb4a-3b46-48f7-829c-f5b580b14d0e
        status: 200 OK
        code: 200
        duration: 47.172ms
    - id: 5
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:54 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - d6d40d7e-19bd-4118-8db2-57ac58e137d9
        status: 200 OK
        code: 200
        duration: 180.770584ms
    - id: 6
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1753
        uncompressed: false
        body: '{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"}'
        headers:
            Content-Length:
                - "1753"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:54 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - b52df8d8-346e-46cb-ba3a-59c02e03cfde
        status: 200 OK
        code: 200
        duration: 31.929375ms
    - id: 7
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:54 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 4fc544bf-a552-4b36-a7ef-3bb9fc874e93
        status: 200 OK
        code: 200
        duration: 187.327125ms
    - id: 8
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1753
        uncompressed: false
        body: '{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"}'
        headers:
            Content-Length:
                - "1753"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:54 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - da48a560-594e-47b4-a0f3-1f0e92bf231d
        status: 200 OK
        code: 200
        duration: 41.073125ms
    - id: 9
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models?order_by=display_rank_asc&page_size=1000
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 50297
        uncompressed: false
        body: '{"models":[{"created_at":"2025-04-04T13:11:00.900800Z","description":"Multimodal model for text generation an image understanding supporting up to 128k context window.","has_eula":false,"id":"5c40e594-d40d-452a-991e-5082225155e1","name":"google/gemma-3-27b-it:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":80000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":54904369444,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T16:45:10.128397Z"},{"created_at":"2025-04-28T18:48:01.860457Z","description":"","has_eula":false,"id":"a19296a6-4cef-447a-99bc-8f6c3ee30df4","name":"TestAccCustomModel_Basic","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-04-30T13:29:24.004776Z","description":"","has_eula":false,"id":"eabb7f74-24a1-4173-911b-26924c1be619","name":"TestAccCustomModel_DeployModelOnServer","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100","quantizations":[{"allowed":true,"max_context_size":18615,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]},{"node_type_name":"H100-2","quantizations":[{"allowed":true,"max_context_size":131072,"quantization_bits":32},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":4}]}]}],"parameter_size_bits":32,"project_id":"d3520a52-2c75-4ba0-bda8-82dd087f07f2","region":"fr-par","size_bytes":59091725346,"status":"ready","tags":["custom"],"updated_at":null},{"created_at":"2025-03-27T16:48:11.513249Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"a51ce791-9546-4c28-aa44-24850d84778b","name":"deepseek/deepseek-r1-distill-llama-8b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":true,"max_context_size":39000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":16070465043,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:49.797687Z"},{"created_at":"2025-03-27T16:48:14.190404Z","description":"Efficient 8B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"b8dc7f2d-95d6-48ae-a076-a99e76b76e1f","name":"deepseek/deepseek-r1-distill-llama-8b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":90000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9093169346,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-04-14T09:05:26.354374Z"},{"created_at":"2025-04-04T15:51:25.414165Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"efcf0b60-999a-4c1e-981e-b68a428c4702","name":"mistral/mistral-small-3.1-24b-instruct-2503:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":75000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-05-09T13:51:56.986698Z"},{"created_at":"2025-04-04T15:51:27.773573Z","description":"Highly efficient multimodal model with vision and chat capabilities supporting up to 128k context window.","has_eula":false,"id":"906c0feb-0eb0-4037-94aa-afd4d845b94f","name":"mistral/mistral-small-3.1-24b-instruct-2503:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":96077777613,"status":"ready","tags":["instruct","chat","vision","featured"],"updated_at":"2025-04-08T14:26:24.388332Z"},{"created_at":"2025-03-27T16:47:41.108667Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"014919c1-00cc-43c2-98f2-4ffd263e6f33","name":"deepseek/deepseek-r1-distill-llama-70b:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":56960,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":141117442445,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:48.796286Z"},{"created_at":"2025-03-27T16:47:42.762505Z","description":"Efficient 70B-param distilled model by DeepSeek, balancing performance and compactness.","has_eula":true,"id":"bbfeeb62-2428-415d-ad0d-537af9aff946","name":"deepseek/deepseek-r1-distill-llama-70b:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679175005,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:35.683881Z"},{"created_at":"2025-03-27T16:48:40.045689Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7205dbce-cc80-4b2a-bb7f-3fd3a804afc3","name":"meta/llama-3.1-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":true,"max_context_size":40000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":true,"max_context_size":131072,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132582323,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:53.288962Z"},{"created_at":"2025-03-27T16:50:12.267422Z","description":"Highly advanced coding model with a 128k context window, excelling in code generation, repairing, and reasoning.","has_eula":false,"id":"a3205fd3-ac4a-47cf-9074-82166d214bac","name":"qwen/qwen2.5-coder-32b-instruct:int8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":35080374444,"status":"ready","tags":["instruct","chat","code","featured"],"updated_at":"2025-05-09T13:52:04.105122Z"},{"created_at":"2025-03-27T16:49:51.968791Z","description":"A large language model customized by NVIDIA in order to improve the helpfulness of generated responses.","has_eula":true,"id":"4e6c9cea-57a1-4215-8a11-24ab51b9d1c8","name":"nvidia/llama-3.1-nemotron-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72679219797,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:01.331740Z"},{"created_at":"2025-05-13T12:13:50.994Z","description":"Best-in-class vision language model by research lab Allen Institute for AI. Available under the Apache 2.0 license.","has_eula":false,"id":"864e7786-4b86-4f4b-8534-25da1fc46a74","name":"allenai/molmo-72b-0924:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":45000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":293245208984,"status":"ready","tags":["instruct","chat","vision"],"updated_at":"2025-05-13T13:34:01.318606Z"},{"created_at":"2025-03-27T16:49:37.342054Z","description":"Efficient 8B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"775cbef7-6527-415d-9e6b-39d574cf39ec","name":"meta/llama-3.1-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":93000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090504772,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:00.700210Z"},{"created_at":"2025-03-27T16:48:15.818596Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"bc10c88e-4d18-4854-8250-77aff4763eca","name":"meta/llama-3-8b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":true,"max_context_size":8192,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":32132572668,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:51.995701Z"},{"created_at":"2025-03-27T16:49:33.359621Z","description":"First generation of 8B-param model by Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b5a94646-9390-4ced-acba-9b078e63a794","name":"meta/llama-3-8b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":9090489355,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:59.473065Z"},{"created_at":"2025-03-27T16:48:42.138410Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"126ad0c4-cfde-4b05-924f-f04c6343ccb2","name":"meta/llama-3.3-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282254830887,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:53.868968Z"},{"created_at":"2025-03-27T16:50:09.605796Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"1678195b-5af6-4c27-8fdc-16aa84c68c34","name":"meta/llama-3.3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72687332869,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-07T10:19:23.153808Z"},{"created_at":"2025-03-27T16:48:35.312110Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"7cbe0417-172a-4601-8940-3b71e4d0c8cb","name":"meta/llama-3.1-70b-instruct:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":60000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":282246710880,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:52.677798Z"},{"created_at":"2025-03-27T16:49:35.836269Z","description":"Efficient 70B-param model by Meta, optimized for multilingual dialogue.","has_eula":true,"id":"03150ad5-de83-4c74-afe0-3eeeb67d71a3","name":"meta/llama-3.1-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":15000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":131072,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665889083,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:52:00.003235Z"},{"created_at":"2025-03-27T16:49:31.715567Z","description":"First generation of 70B-param model from Meta, fine-tuned for instruction and automation.","has_eula":true,"id":"b0c5a8fe-5c9e-49cc-942a-6c4ebaadde67","name":"meta/llama-3-70b-instruct:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":8192,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":72665872089,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:58.899458Z"},{"created_at":"2025-03-27T16:49:17.458153Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"1e555754-47fb-4dba-a82c-66f3f1fa9294","name":"mistral/mistral-small-24b-instruct-2501:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":94321843451,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.176379Z"},{"created_at":"2025-03-27T16:50:07.300436Z","description":"A state-of-the-art 24B model with a 32k context window, designed for multilingual chat and agentic applications.","has_eula":false,"id":"7bb28f2c-3719-4d71-9bcb-17db392a7118","name":"mistral/mistral-small-24b-instruct-2501:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":20000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":24938988520,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-09T13:51:55.726891Z"},{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"},{"created_at":"2025-03-27T16:49:14.593008Z","description":"A very efficient language model by Mistral AI, optimized for instruction-following tasks. Available under the Apache 2.0 license.","has_eula":false,"id":"bf6be106-c53d-4b93-bb33-1a4bd4d0b573","name":"mistral/mistral-7b-instruct-v0.3:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":28995471292,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:54.595513Z"},{"created_at":"2025-03-27T16:50:06.301430Z","description":"A state-of-the-art 12B model with a 128k context window, designed for multilingual chat applications.","has_eula":false,"id":"07681325-c743-4796-8b7d-1f0b35d4a8e0","name":"mistral/mistral-nemo-instruct-2407:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":128000,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":13605604415,"status":"ready","tags":["instruct","chat","featured"],"updated_at":"2025-05-06T15:17:43.837103Z"},{"created_at":"2025-03-27T16:50:08.291821Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"1aa87d1e-9996-4c54-aa1c-5b900bf59fd4","name":"mistral/mixtral-8x7b-instruct-v0.1:fp8","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":8,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":46970879717,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:52:02.960404Z"},{"created_at":"2025-03-27T16:49:19.120192Z","description":"A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.","has_eula":false,"id":"11ed6599-f460-4e41-b266-87bc9a108fdd","name":"mistral/mixtral-8x7b-instruct-v0.1:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":true,"max_context_size":32768,"quantization_bits":8},{"allowed":true,"max_context_size":32768,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":190483875108,"status":"ready","tags":["instruct","chat"],"updated_at":"2025-05-09T13:51:57.661626Z"},{"created_at":"2025-03-27T16:46:54.314987Z","description":"An embedding model spanning a broad range of languages and state-of-the-art results on multilingual benchmarks.","has_eula":true,"id":"d58efec4-b667-48e2-8ad8-bcc26c175ae6","name":"baai/bge-multilingual-gemma2:fp32","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":true,"max_context_size":8192,"quantization_bits":32}]}]}],"parameter_size_bits":32,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":36989461520,"status":"ready","tags":["embedding","featured"],"updated_at":"2025-03-27T17:40:09.534954Z"}],"total_count":29}'
        headers:
            Content-Length:
                - "50297"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:55 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - 90940d78-8556-4b3a-9779-15fc4edf8144
        status: 200 OK
        code: 200
        duration: 201.329542ms
    - id: 10
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        transfer_encoding: []
        trailer: {}
        host: api.scaleway.com
        remote_addr: ""
        request_uri: ""
        body: ""
        form: {}
        headers:
            User-Agent:
                - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.24.1; darwin; arm64) terraform-provider/develop terraform/terraform-tests
        url: https://api.scaleway.com/inference/v1/regions/fr-par/models/1999f4f5-f038-4039-94ba-11a851917df5
        method: GET
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: 1753
        uncompressed: false
        body: '{"created_at":"2025-04-15T10:51:31.291792Z","description":"Vision language model able to analyze images and offer insights without compromising on instruction following.","has_eula":false,"id":"1999f4f5-f038-4039-94ba-11a851917df5","name":"mistral/pixtral-12b-2409:bf16","nodes_support":[{"nodes":[{"node_type_name":"L4","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":false,"max_context_size":0,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"L40S","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":50000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]},{"node_type_name":"H100-2","quantizations":[{"allowed":false,"max_context_size":0,"quantization_bits":4},{"allowed":false,"max_context_size":0,"quantization_bits":8},{"allowed":true,"max_context_size":128000,"quantization_bits":16},{"allowed":false,"max_context_size":0,"quantization_bits":32}]}]}],"parameter_size_bits":16,"project_id":"00000000-0000-0000-0000-000000000000","region":"fr-par","size_bytes":25384844091,"status":"ready","tags":["vision","chat","featured"],"updated_at":"2025-05-09T13:51:58.281971Z"}'
        headers:
            Content-Length:
                - "1753"
            Content-Security-Policy:
                - default-src 'none'; frame-ancestors 'none'
            Content-Type:
                - application/json
            Date:
                - Wed, 14 May 2025 16:04:55 GMT
            Server:
                - Scaleway API Gateway (fr-par-1;edge02)
            Strict-Transport-Security:
                - max-age=63072000
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - DENY
            X-Request-Id:
                - e1e5daa0-92d2-46b6-90a1-12ef87a83d59
        status: 200 OK
        code: 200
        duration: 34.163333ms
